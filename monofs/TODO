WHEN KEY IS REMOVED FROM CACHE it should be removed from database as well 
ADD proper fs testing

create delete the same file
dcreate / remove dir and file create symlink etc
ex:  plus add # as separation betwean key and value
package main

import (
	"encoding/base64"
	"io/ioutil"
	"os"
	"strings"
)

func encodeToFile(data ...[]byte) error {
	file, err := os.Create("data.b64")
	if err != nil {
		return err
	}
	defer file.Close()

	for _, d := range data {
		enc := base64.StdEncoding.EncodeToString(d)
		_, err := file.WriteString(enc + "\n")
		if err != nil {
			return err
		}
	}

	return nil
}

func decodeFromFile() ([][]byte, error) {
	file, err := os.Open("data.b64")
	if err != nil {
		return nil, err
	}
	defer file.Close()

	data, err := ioutil.ReadAll(file)
	if err != nil {
		return nil, err
	}

	var result [][]byte
	for _, line := range strings.Split(string(data), "\n") {
		if line == "" {
			continue
		}
		dec, err := base64.StdEncoding.DecodeString(line)
		if err != nil {
			return nil, err
		}
		result = append(result, dec)
	}

	return result, nil
}

func main() {
	// example usage
	data1 := []byte("hello")
	data2 := []byte("world")
	if err := encodeToFile(data1, data2); err != nil {
		panic(err)
	}

	data, err := decodeFromFile()
	if err != nil {
		panic(err)
	}
	for _, d := range data {
		println(string(d))
	}
}


package main

func encodeParityCodes(data []byte, numParity int) [][]byte {
	var codes [][]byte

	// Add original data as first code
	codes = append(codes, data)

	// Compute parity codes
	for i := 0; i < numParity; i++ {
		parity := make([]byte, len(data))
		for j := range data {
			for k := 0; k < len(codes); k++ {
				parity[j] ^= codes[k][j]
			}
		}
		codes = append(codes, parity)
	}

	return codes
}

func decodeParityCodes(codes [][]byte) []byte {
	var result []byte
	if len(codes) == 0 {
		return result
	}

	// Compute data length
	dataLen := len(codes[0])
	if dataLen == 0 {
		return result
	}

	// Decode data using XOR
	for i := 0; i < dataLen; i++ {
		var b byte
		for j := 0; j < len(codes); j++ {
			b ^= codes[j][i]
		}
		result = append(result, b)
	}

	return result
}

func main() {
	// example usage
	data := []byte("hello world")
	numParity := 3
	codes := encodeParityCodes(data, numParity)
	println("Encoded codes:")
	for _, code := range codes {
		println(string(code))
	}

	decoded := decodeParityCodes(codes)
	println("Decoded data:")
	println(string(decoded))
}

package main

import (
	"bytes"
	"math/rand"
	"testing"
)

func TestXORBasedParityCodes(t *testing.T) {
	// Example data and parameters
	data := []byte("hello world")
	numParity := 3

	// Create parity codes
	codes := encodeParityCodes(data, numParity)

	// Simulate random corruption
	r := rand.New(rand.NewSource(42))
	for i := 0; i < len(codes); i++ {
		for j := 0; j < len(codes[i]); j++ {
			if r.Intn(10) == 0 {
				// Flip a random bit with 10% probability
				codes[i][j] ^= 0x01
			}
		}
	}

	// Decode parity codes
	decoded := decodeParityCodes(codes)

	// Check if decoded data matches original data
	if !bytes.Equal(decoded, data) {
		t.Errorf("Decoded data does not match original data: %q vs %q", decoded, data)
	}
}

Create wal + cache intergration testings 
testing case should cover rapiod change in generation  of wal files	
